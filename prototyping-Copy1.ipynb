{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import app.pipeliner.pipedev as piper\n",
    "import app.pipeliner.registry as rg\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import simplejson as json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = piper.TextPipliner(\"pickle0003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done  96 out of  96 | elapsed:   21.9s finished\n",
      "c:\\users\\cdl\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "c:\\users\\cdl\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(GridSearchCV(cv=None, error_score='raise',\n",
       "        estimator=Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=50000, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         stri...   penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "        verbose=0, warm_start=False))]),\n",
       "        fit_params={}, iid=True, n_jobs=-1,\n",
       "        param_grid={'vect__max_features': (None, 5000, 10000, 50000), 'vect__ngram_range': ((1, 1), (1, 2)), 'tfidf__norm': ('l1', 'l2'), 'clf__alpha': (1e-05, 1e-06)},\n",
       "        pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "        scoring=None, verbose=1), './app/pipeliner/store/pickle0003')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp.set_pipeline(Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier()),\n",
    "]))\n",
    "tp.set_categories([\n",
    "    'alt.atheism',\n",
    "    'talk.religion.misc',\n",
    "])\n",
    "\n",
    "tp.set_search_params({\n",
    "    \"verbose\": 1,\n",
    "    \"n_jobs\": -1,\n",
    "    \"param_grid\": {\n",
    "    #'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    #'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__alpha': (0.00001, 0.000001),\n",
    "    #'clf__penalty': ('l2', 'elasticnet'),\n",
    "    #'clf__n_iter': (10, 50, 80),\n",
    "}})\n",
    "tp.run(persist_dir=\"./app/pipeliner/store/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a new PickleRegister at \"./app/pipeliner/register.json\"\n",
    "# The pickles are being persisted to \"./app/pipeliner/store/\"\n",
    "reg = rg.PickleRegister(\"./app/pipeliner/register.json\", \n",
    "                  \"./app/pipeliner/store/\", new_register=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The TextPipeliner as_registry() method takes a filepath to persist the metadata\n",
    "# and a description of the pickle. It returns a valid argument for the PickleRegister\n",
    "# new_entry() method.\n",
    "item = tp.as_registry(\"./app/pipeliner/store/pickle0003.json\", \"A\"\n",
    "                      \" pipeline tuned on a broad parameter space, \"\n",
    "                      \"trained on two categories in the newsgroup20 corpus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_entry() also expects a pickle_type (\"pipeline\") and can accept an id kwarg\n",
    "reg.new_entry(item, \"pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'register': {'pickle0003': {'id': 'pickle0003',\n",
       "   'payload': {'answer_key': {0: 'alt.atheism', 1: 'talk.religion.misc'},\n",
       "    'components': ['CountVectorizer', 'TfidfTransformer', 'SGDClassifier'],\n",
       "    'description': 'A pipeline tuned on a broad parameter space, trained on two categories in the newsgroup20 corpus.',\n",
       "    'name': 'pickle0003',\n",
       "    'score': 0.9369894982497082,\n",
       "    'search_params': {'n_jobs': -1,\n",
       "     'param_grid': {'clf__alpha': (1e-05, 1e-06),\n",
       "      'tfidf__norm': ('l1', 'l2'),\n",
       "      'vect__max_features': (None, 5000, 10000, 50000),\n",
       "      'vect__ngram_range': ((1, 1), (1, 2))},\n",
       "     'verbose': 1}},\n",
       "   'pickletype': 'pipeline'}}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg._register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': []}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg._ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_map = reg.load_pickles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pickle0003': Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=50000, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         stri...   penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "        verbose=0, warm_start=False))])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg._pickletypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'register': {'pickle0003': {'id': 'pickle0003',\n",
       "   'payload': {'answer_key': {'0': 'alt.atheism', '1': 'talk.religion.misc'},\n",
       "    'components': ['CountVectorizer', 'TfidfTransformer', 'SGDClassifier'],\n",
       "    'description': 'A pipeline tuned on a broad parameter space, trained on two categories in the newsgroup20 corpus.',\n",
       "    'name': 'pickle0003',\n",
       "    'score': 0.9369894982497082,\n",
       "    'search_params': {'n_jobs': -1,\n",
       "     'param_grid': {'clf__alpha': [1e-05, 1e-06],\n",
       "      'tfidf__norm': ['l1', 'l2'],\n",
       "      'vect__max_features': [None, 5000, 10000, 50000],\n",
       "      'vect__ngram_range': [[1, 1], [1, 2]]},\n",
       "     'verbose': 1}},\n",
       "   'pickletype': 'pipeline'}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./app/pipeliner/register.json\", \"r\") as registry:\n",
    "    reg = json.load(registry)\n",
    "reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "regObject = reg[\"register\"][\"pickle0003\"]\n",
    "regObject[\"payload\"][\"description\"] = 'A pipeline tuned on a broad parameter space, trained on all the categories in the newsgroup20 corpus.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = rg.PickleRegister(\"./app/pipeliner/register.json\", \n",
    "                  \"./app/pipeliner/store/\")\n",
    "reg.update_entry(regObject)\n",
    "pickle_map = reg.load_pickles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'register': {'pickle0003': {'id': 'pickle0003',\n",
       "   'payload': {'answer_key': {'0': 'alt.atheism', '1': 'talk.religion.misc'},\n",
       "    'components': ['CountVectorizer', 'TfidfTransformer', 'SGDClassifier'],\n",
       "    'description': 'A pipeline tuned on a broad parameter space, trained on all the categories in the newsgroup20 corpus.',\n",
       "    'name': 'pickle0003',\n",
       "    'score': 0.9369894982497082,\n",
       "    'search_params': {'n_jobs': -1,\n",
       "     'param_grid': {'clf__alpha': [1e-05, 1e-06],\n",
       "      'tfidf__norm': ['l1', 'l2'],\n",
       "      'vect__max_features': [None, 5000, 10000, 50000],\n",
       "      'vect__ngram_range': [[1, 1], [1, 2]]},\n",
       "     'verbose': 1}},\n",
       "   'pickletype': 'pipeline'}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg._register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1152 candidates, totalling 3456 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   43.4s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3456 out of 3456 | elapsed: 13.1min finished\n",
      "c:\\users\\cdl\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "c:\\users\\cdl\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "tp2 = piper.TextPipliner(\"pickle0002\")\n",
    "tp2.set_pipeline(Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier()),\n",
    "]))\n",
    "tp2.set_categories([\n",
    "    'alt.atheism',\n",
    "    'talk.religion.misc',\n",
    "])\n",
    "tp2.set_search_params({\n",
    "    \"verbose\": 1,\n",
    "    \"n_jobs\": -1,\n",
    "    \"param_grid\": {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__alpha': (0.00001, 0.000001),\n",
    "    'clf__penalty': ('l2', 'elasticnet'),\n",
    "    'clf__n_iter': (10, 50, 80),\n",
    "}})\n",
    "gsCV = tp2.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = tp2.as_registry(\"./app/pipeliner/store/pickle0002.json\", \"A\"\n",
    "                      \" pipeline tuned on a broad parameter space, \"\n",
    "                      \"trained on 2 categories ('alt.atheism', 'talk.religion.misc')\"\n",
    "                      \"in the newsgroup20 corpus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = rg.PickleRegister(\"./app/pipeliner/register.json\", \n",
    "                  \"./app/pipeliner/store/\")\n",
    "reg.new_entry(item, \"pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pickle0002': Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=0.75, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "         stri...   penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "        verbose=0, warm_start=False))]),\n",
       " 'pickle0003': Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=50000, min_df=1,\n",
       "         ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "         stri...   penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "        verbose=0, warm_start=False))])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_map = reg.load_pickles()\n",
    "pickle_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\"{\\\\\"register\\\\\": {\\\\\"pickle0003\\\\\": {\\\\\"id\\\\\": \\\\\"pickle0003\\\\\", \\\\\"pickletype\\\\\": \\\\\"pipeline\\\\\", \\\\\"payload\\\\\": {\\\\\"name\\\\\": \\\\\"pickle0003\\\\\", \\\\\"answer_key\\\\\": {\\\\\"0\\\\\": \\\\\"alt.atheism\\\\\", \\\\\"1\\\\\": \\\\\"talk.religion.misc\\\\\"}, \\\\\"components\\\\\": [\\\\\"CountVectorizer\\\\\", \\\\\"TfidfTransformer\\\\\", \\\\\"SGDClassifier\\\\\"], \\\\\"score\\\\\": 0.9369894982497082, \\\\\"search_params\\\\\": {\\\\\"verbose\\\\\": 1, \\\\\"n_jobs\\\\\": -1, \\\\\"param_grid\\\\\": {\\\\\"vect__max_features\\\\\": [null, 5000, 10000, 50000], \\\\\"vect__ngram_range\\\\\": [[1, 1], [1, 2]], \\\\\"tfidf__norm\\\\\": [\\\\\"l1\\\\\", \\\\\"l2\\\\\"], \\\\\"clf__alpha\\\\\": [1e-05, 1e-06]}}, \\\\\"description\\\\\": \\\\\"A pipeline tuned on a broad parameter space, trained on two categories in the newsgroup20 corpus.\\\\\"}}}}\"'\n"
     ]
    }
   ],
   "source": [
    "resp = requests.get(\"http://localhost/api/pickleregister\")\n",
    "resp.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"prediction\": \"talk.religion.misc\", \"register\": {\"id\": \"pickle0003\", \"pickletype\": \"pipeline\", \"payload\": {\"name\": \"pickle0003\", \"answer_key\": {\"0\": \"alt.atheism\", \"1\": \"talk.religion.misc\"}, \"components\": [\"CountVectorizer\", \"TfidfTransformer\", \"SGDClassifier\"], \"score\": 0.9369894982497082, \"search_params\": {\"verbose\": 1, \"n_jobs\": -1, \"param_grid\": {\"vect__max_features\": [null, 5000, 10000, 50000], \"vect__ngram_range\": [[1, 1], [1, 2]], \"tfidf__norm\": [\"l1\", \"l2\"], \"clf__alpha\": [1e-05, 1e-06]}}, \"description\": \"A pipeline tuned on a broad parameter space, trained on two categories in the newsgroup20 corpus.\"}}}'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst = requests.post(\"http://localhost/api/predict\", json= {\"id\": \"pickle0003\",\n",
    "                                                               \"text\": article_tester})\n",
    "pst.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'register': {}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.delete_entry(\"pickle0003\")\n",
    "reg._register\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'pickle0001',\n",
       " 'payload': {'answer_key': {'0': 'alt.atheism', '1': 'talk.religion.misc'},\n",
       "  'components': ['CountVectorizer', 'TfidfTransformer', 'SGDClassifier'],\n",
       "  'description': 'A pipeline tuned on a broad parameter space, trained on alt.atheism and talk.religion.misc.',\n",
       "  'name': 'pickle0001',\n",
       "  'score': 0.9381563593932322,\n",
       "  'search_params': {'n_jobs': -1,\n",
       "   'param_grid': {'clf__alpha': [1e-05, 1e-06],\n",
       "    'clf__penalty': ['l2', 'elasticnet'],\n",
       "    'tfidf__norm': ['l1', 'l2'],\n",
       "    'vect__max_features': [None, 5000, 10000, 50000],\n",
       "    'vect__ngram_range': [[1, 1], [1, 2]]},\n",
       "   'verbose': 1}},\n",
       " 'pickletype': 'pipeline'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import simplejson as json\n",
    "with open(\"./app/pipeliner/register.json\", 'rb') as f:\n",
    "    loaded = json.load(f)\n",
    "loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cdl\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = pickle_map[\"pickle0001\"]\n",
    "est.predict([article_tester])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'pickle0001',\n",
       "  'payload': {'answer_key': {0: 'alt.atheism', 1: 'talk.religion.misc'},\n",
       "   'components': ['CountVectorizer', 'TfidfTransformer', 'SGDClassifier'],\n",
       "   'description': 'A pipeline tuned on a broad parameter space, trained on alt.atheism and talk.religion.misc.',\n",
       "   'name': 'pickle0001',\n",
       "   'score': 0.9381563593932322,\n",
       "   'search_params': {'n_jobs': -1,\n",
       "    'param_grid': {'clf__alpha': (1e-05, 1e-06),\n",
       "     'clf__penalty': ('l2', 'elasticnet'),\n",
       "     'tfidf__norm': ('l1', 'l2'),\n",
       "     'vect__max_features': (None, 5000, 10000, 50000),\n",
       "     'vect__ngram_range': ((1, 1), (1, 2))},\n",
       "    'verbose': 1}},\n",
       "  'pickletype': 'pipeline'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg._register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'payload': [{'answer_key': {'0': 'alt.atheism', '1': 'talk.religion.misc'},\n",
       "    'components': ['CountVectorizer', 'TfidfTransformer', 'SGDClassifier'],\n",
       "    'description': ['A dummy'],\n",
       "    'name': ['pickle0001'],\n",
       "    'score': [0.9463243873978997],\n",
       "    'search_params': [{'n_jobs': -1,\n",
       "      'param_grid': {'clf__n_iter': [10, 50, 80],\n",
       "       'tfidf__norm': ['l1', 'l2'],\n",
       "       'vect__max_df': [0.5, 0.75, 1.0],\n",
       "       'vect__max_features': [None, 5000, 10000, 50000]},\n",
       "      'verbose': 1}]}],\n",
       "  'pickletype': 'pipeline'},\n",
       " {'id': 2,\n",
       "  'payload': {'answer_key': {'0': 'alt.atheism', '1': 'talk.religion.misc'},\n",
       "   'components': ['CountVectorizer', 'TfidfTransformer', 'SGDClassifier'],\n",
       "   'description': ['A dummy'],\n",
       "   'name': ['pickle0001'],\n",
       "   'score': [0.9463243873978997],\n",
       "   'search_params': [{'n_jobs': -1,\n",
       "     'param_grid': {'clf__n_iter': [10, 50, 80],\n",
       "      'tfidf__norm': ['l1', 'l2'],\n",
       "      'vect__max_df': [0.5, 0.75, 1.0],\n",
       "      'vect__max_features': [None, 5000, 10000, 50000]},\n",
       "     'verbose': 1}]},\n",
       "  'pickletype': 'pipeline'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./app/pipeliner/store/pickle0001.json\", 'w') as file:\n",
    "\n",
    "    json.dump([\n",
    "        {\"id\": 1, \"pickletype\": \"pipeline\", \"payload\": [{'answer_key': {'0': 'alt.atheism', '1': 'talk.religion.misc'},\n",
    "     'components': ['CountVectorizer', 'TfidfTransformer', 'SGDClassifier'],\n",
    "     'description': ['A dummy'],\n",
    "     'name': ['pickle0001'],\n",
    "     'score': [0.9463243873978997],\n",
    "     'search_params': [{'n_jobs': -1,\n",
    "       'param_grid': {'clf__n_iter': [10, 50, 80],\n",
    "        'tfidf__norm': ['l1', 'l2'],\n",
    "        'vect__max_df': [0.5, 0.75, 1.0],\n",
    "        'vect__max_features': [None, 5000, 10000, 50000]},\n",
    "       'verbose': 1}]}]},\n",
    "    {\"id\": 2, \"pickletype\": \"pipeline\", \"payload\": {'answer_key': {'0': 'alt.atheism', '1': 'talk.religion.misc'},\n",
    "     'components': ['CountVectorizer', 'TfidfTransformer', 'SGDClassifier'],\n",
    "     'description': ['A dummy'],\n",
    "     'name': ['pickle0001'],\n",
    "     'score': [0.9463243873978997],\n",
    "     'search_params': [{'n_jobs': -1,\n",
    "       'param_grid': {'clf__n_iter': [10, 50, 80],\n",
    "        'tfidf__norm': ['l1', 'l2'],\n",
    "        'vect__max_df': [0.5, 0.75, 1.0],\n",
    "        'vect__max_features': [None, 5000, 10000, 50000]},\n",
    "       'verbose': 1}]}}], file)\n",
    "\n",
    "with open(\"./app/pipeliner/store/pickle0001.json\", 'rb') as f:\n",
    "    loaded = json.load(f)\n",
    "loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([0, 1, 0, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./app/pipeliner/registry.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 documents\n",
      "20 categories\n",
      "\n",
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (1e-05, 1e-06),\n",
      " 'clf__n_iter': (10, 50, 80),\n",
      " 'clf__penalty': ('l2', 'elasticnet'),\n",
      " 'tfidf__norm': ('l1', 'l2'),\n",
      " 'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0),\n",
      " 'vect__max_features': (None, 5000, 10000, 50000),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 3 folds for each of 1152 candidates, totalling 3456 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 26.2min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 51.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 109.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 193.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed: 234.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed: 320.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3456 out of 3456 | elapsed: 377.5min finished\n",
      "c:\\users\\cdl\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 22760.330s\n",
      "\n",
      "Best score: 0.925\n",
      "Best parameters set:\n",
      "\tclf__alpha: 1e-05\n",
      "\tclf__n_iter: 50\n",
      "\tclf__penalty: 'elasticnet'\n",
      "\ttfidf__norm: 'l2'\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: None\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Load some categories from the training set\n",
    "categories = [\n",
    "    'alt.atheism',\n",
    "    'talk.religion.misc',\n",
    "]\n",
    "# Uncomment the following to do the analysis on all the categories\n",
    "categories = None\n",
    "\n",
    "data = fetch_20newsgroups(subset='train', categories=categories)\n",
    "print(\"%d documents\" % len(data.filenames))\n",
    "print(\"%d categories\" % len(data.target_names))\n",
    "print()\n",
    "\n",
    "###############################################################################\n",
    "# define a pipeline combining a text feature extractor with a simple\n",
    "# classifier\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier()),\n",
    "])\n",
    "\n",
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__alpha': (0.00001, 0.000001),\n",
    "    'clf__penalty': ('l2', 'elasticnet'),\n",
    "    'clf__n_iter': (10, 50, 80),\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(data.data, data.target)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.5, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip...ty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.set_params(**grid_search.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cdl\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.5, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip...ty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(data.data, data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_tester = \"\"\"One of the surprises from AMD’s first year of the newest x86 Zen architecture was the launch of the Threadripper platform. Despite the mainstream Ryzen processors already taking a devastating stab into the high-end desktop market, AMD’s Threadripper offered more cores at a workstation-friendly price. For 2018, the next generation is going to be using AMD’s updated 12nm Zeppelin dies, as well as including a few new tweaks into the system including better boost and faster caches.\n",
    "\n",
    "This article is still a work in progress, and will be updated as more news comes in.\n",
    "\n",
    "\n",
    "\n",
    "AMD’s Zeppelin silicon has 8 cores, and the first generation Threadripper uses two of them to get to the top-SKU of 16-cores. Inside the CPU however, there are four pieces of silicon: two active and two inactive. For this second generation of Threadripper, called Threadripper 2 or the Threadripper 2000-series, AMD is going to make these inactive dies into active ones, and substantially increase the core count for the high-end desktop and workstation user.\n",
    "\n",
    "\n",
    "\n",
    "At the AMD press event at Computex, it was revealed that these new processors would have up to 32 cores in total, mirroring the 32-core versions of EPYC. On EPYC, those processors have four active dies, with eight active cores on each die (four for each CCX). On EPYC however, there are eight memory channels, and AMD’s X399 platform only has support for four channels. For the first generation this meant that each of the two active die would have two memory channels attached – in the second generation Threadripper this is still the case: the two now ‘active’ parts of the chip do not have direct memory access.\n",
    "\n",
    "\n",
    "\n",
    "This technically adds latency to the platform, however AMD is of the impression that for all but the most memory bound tasks, this should not be an issue (usually it is suggested to just go buy an EPYC for those workloads). While it does put more pressure on the internal Infinity Fabric, AMD ultimately designed Infinity Fabric for scalable scenarios like this between different silicon with different levels of cache and memory access.\n",
    "\n",
    "\n",
    "\n",
    "Update: AMD has just published a full copy of their slide deck for the Threadripper 2 presentation. In it are a few interesting factoids.\n",
    "\n",
    "AMD Threadripper CPUs\n",
    " \tThreadripper\n",
    "2\n",
    "32-Core Sample\tThreadripper\n",
    "2\n",
    "24-Core Sample\tThreadripper\n",
    "1950X\tThreadripper\n",
    "1920X\n",
    "Socket\tTR4 (LGA)\n",
    "4094-pin\n",
    "CPU Architecture\tZen+\tZen+\tZen\tZen\n",
    "Cores/Threads\t32 / 64\t24 / 48\t16 / 32\t12 / 24\n",
    "Base Frequency\t3.0 GHz\t3.0 GHz\t3.4 GHz\t3.5 GHz\n",
    "Turbo Frequency\t3.4 GHz (WIP)\t3.4 GHz (WIP)\t4.0 GHz\t4.0 GHz\n",
    "L3 Cache\t64 MB ?\t48 MB ?\t32 MB\t32 MB\n",
    "TDP\t250W\t250W\t180W\t180W\n",
    "PCIe 3.0 Lanes\t60 + 4\n",
    "Chipset Support\tX399\n",
    "Memory Channels\t4\n",
    "Both the 24-core and 32-core sample CPUs are clocked at 3.0GHz base and 3.4GHz all-core turbo, with the latter being a work-in-progress according to the company.\n",
    "The 32-core system was equipped with DDR4-3200 memory. This is notable because the Ryzen processors based on the same 12nm Zeppelin dies officially max out at DDR4-2933.\n",
    "The codename for the processor family is listed as \"Colfax\". This is the first we've heard this codename from AMD.\n",
    "Despite the high TDP, both CPUs used in AMD's demos were air-cooled, using AMD's Wraith Ripper Air Cooler\n",
    "Also announced at the presentation is the state of play of motherboards. According to the motherboard vendors These new Threadripper 2000-series processors will have a peak TDP rating of 250W, which is much higher than 180W we saw on the 1950X. We have been told by partners that the 250W rating is actually conservative, and users should expect lower power consumption in most scenarios. Nonetheless, it was stated by several motherboard vendors that some of the current X399 motherboards on the market might struggle with power delivery to the new parts, and so we are likely to see a motherboard refresh. That is not saying that the current X399 offerings will not work, however they might not offer overclocking to the level that users might expect. At Computex there are new X399 refresh motherboards being demonstrated by a few companies, and we will report on them in due course. Other specifications are expected to match the previous generation, such as PCIe lane counts, despite the newly active dies.\n",
    "\n",
    "\n",
    "MSI's 19-phase X399 Refresh Motherboard\n",
    "\n",
    "The launch for these new processors, according to our moles is in early August. This aligns with what AMD stated at the beginning of the year at CES, and is almost a year from the original Threadripper launch.\n",
    "\n",
    "Pricing on the processors is set to be revealed either today or closer to the launch time. We will update this piece as more information comes in.\n",
    "\n",
    "It will be interesting if AMD is going to go through the ‘unboxing’ embargo this time around, or just jump straight to full performance reviews. As always, come to AnandTech for the full story.\n",
    "\n",
    "\n",
    "GIGABYTE's new X399 Refresh Motherboard\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cdl\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "c:\\users\\cdl\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "c:\\users\\cdl\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py:54: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "prediction = pipeline.predict([article_tester])\n",
    "\n",
    "transform = pipeline.transform([article_tester])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'alt.atheism',\n",
       " 1: 'comp.graphics',\n",
       " 2: 'comp.os.ms-windows.misc',\n",
       " 3: 'comp.sys.ibm.pc.hardware',\n",
       " 4: 'comp.sys.mac.hardware',\n",
       " 5: 'comp.windows.x',\n",
       " 6: 'misc.forsale',\n",
       " 7: 'rec.autos',\n",
       " 8: 'rec.motorcycles',\n",
       " 9: 'rec.sport.baseball',\n",
       " 10: 'rec.sport.hockey',\n",
       " 11: 'sci.crypt',\n",
       " 12: 'sci.electronics',\n",
       " 13: 'sci.med',\n",
       " 14: 'sci.space',\n",
       " 15: 'soc.religion.christian',\n",
       " 16: 'talk.politics.guns',\n",
       " 17: 'talk.politics.mideast',\n",
       " 18: 'talk.politics.misc',\n",
       " 19: 'talk.religion.misc'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{i: y for i, y in enumerate(data.target_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pickle0001']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(pipeline, filename=\"pickle0001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = joblib.load(filename=\"./pickle0001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "[name[1].__class__.__name__ for name in pipeline.steps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cdl\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "c:\\users\\cdl\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "c:\\users\\cdl\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py:54: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "inc = pipeline.transform(data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cdl\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "vect = pipeline.named_steps['vect'].transform([article_tester])\n",
    "tfi = pipeline.named_steps['tfidf'].transform(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x1181775 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 658 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(<1x1181775 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 658 stored elements in Compressed Sparse Row format>, dtype=object)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(tfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pipeline.named_steps['vect'].get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "831"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(article_tester.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tops = zip(np.array(pipeline.named_steps['vect'].get_feature_names()), tfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = pipeline.named_steps['clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = pipeline.transform([article_tester])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x202335 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 505 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
